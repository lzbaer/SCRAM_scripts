{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff73bd50-68c6-4a9f-b429-5271b7586173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries: 9911\n",
      "Number of entries with recorded loss: 276\n",
      "Number of entries with recorded loss && employee count: 208\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "VCDB_FILE_JSON = \"data/joined/vcdb_1-of-1.json\"\n",
    "VCDB_EXCEL_OUTPUT = \"vcdb_regression.xlsx\"\n",
    "\n",
    "NAIC_CODES = {\n",
    "    \"11\": \"Agriculture, Forestry, Fishing and Hunting\",\n",
    "    \"21\": \"Mining\",\n",
    "    \"22\": \"Utilities\",\n",
    "    \"23\": \"Construction\",\n",
    "    \"3\": \"Manufacturing\",\n",
    "    \"42\": \"Wholesale Trade\",\n",
    "    \"44\": \"Retail Trade\",\n",
    "    \"45\": \"Retail Trade\",\n",
    "    \"48\": \"Transportation and Warehousing\",\n",
    "    \"49\": \"Transportation and Warehousing\",\n",
    "    \"51\": \"Information\",\n",
    "    \"52\": \"Finance and Insurance\",\n",
    "    \"53\": \"Real Estate Rental and Leasing\",\n",
    "    \"54\": \"Professional, Scientific, and Technical Services\",\n",
    "    \"55\": \"Management of Companies and Enterprises\",\n",
    "    \"56\": \"Administrative and Support and Waste... Services\",\n",
    "    \"61\": \"Educational Services\",\n",
    "    \"62\": \"Health Care and Social Assistance\",\n",
    "    \"71\": \"Arts, Entertainment, and Recreation\",\n",
    "    \"72\": \"Accommodation and Food Services\",\n",
    "    \"81\": \"Other Services (except Public Administration)\",\n",
    "    \"92\": \"Public Administration\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_industry(d):\n",
    "    industry_code = d[\"victim\"][\"industry\"]\n",
    "    if industry_code[0:2] in NAIC_CODES:\n",
    "        return NAIC_CODES[industry_code[0:2]]\n",
    "    if industry_code[0] in NAIC_CODES:\n",
    "        return NAIC_CODES[industry_code[0]]\n",
    "    return \"Unknown\"\n",
    "\n",
    "# filter for identified victim\n",
    "def filter_for_victim_id(data):\n",
    "    filtered = []\n",
    "    for idx, d in enumerate(data):\n",
    "        if \"victim_id\" in d[\"victim\"] and d[\"victim\"][\"victim_id\"] != \"Unknown\":\n",
    "            filtered.append(d)\n",
    "    return filtered\n",
    "\n",
    "# filter for recorded loss in dollars\n",
    "def filter_for_recorded_loss(data):\n",
    "    filtered = []\n",
    "    for idx, d in enumerate(data):\n",
    "        if \"impact\" in d and (\"overall_amount\" in d[\"impact\"] or \"overall_min_amount\" in d[\"impact\"] or \"overall_max_amount\" in d[\"impact\"]):\n",
    "            if \"iso_currency_code\" in d[\"impact\"] and d[\"impact\"][\"iso_currency_code\"] != \"USD\":\n",
    "                  continue\n",
    "            filtered.append(d)\n",
    "    return filtered\n",
    "\n",
    "def average_from_range(text):\n",
    "    \"\"\"\n",
    "    Checks if the string contains a pattern of the form \"[number] to [number]\",\n",
    "    and returns the average of those two numbers.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input string.\n",
    "    \n",
    "    Returns:\n",
    "    float: The average of the two numbers, or None if no match is found.\n",
    "    \"\"\"\n",
    "    # Define the regular expression pattern to match \"[number] to [number]\"\n",
    "    pattern = r\"(\\d+)\\s*to\\s*(\\d+)\"\n",
    "    \n",
    "    # Search for the pattern in the input text\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the numbers from the match\n",
    "        num1 = int(match.group(1))\n",
    "        num2 = int(match.group(2))\n",
    "        \n",
    "        # Calculate the average of the two numbers\n",
    "        average = (num1 + num2) / 2\n",
    "        \n",
    "        return int(average)\n",
    "    else:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "\n",
    "def filter_for_victim_employee_count(data):\n",
    "    filtered = []\n",
    "    for idx, d in enumerate(data):\n",
    "        if \"victim\" in d and \"employee_count\" in d[\"victim\"]:\n",
    "            employee_count = d[\"victim\"][\"employee_count\"]\n",
    "            if employee_count == \"Unknown\":\n",
    "                continue\n",
    "            # average_from_range(d[\"victim\"][\"employee_count\"])\n",
    "            count = average_from_range(employee_count)\n",
    "            if  count == None:\n",
    "                if employee_count == \"Over 100000\":\n",
    "                    count = 100000\n",
    "                elif employee_count == \"Large\":\n",
    "                    count = 5000\n",
    "                elif employee_count == \"Small\":\n",
    "                    count = 500\n",
    "                else:\n",
    "                    print(d[\"victim\"][\"employee_count\"])\n",
    "            d[\"victim\"][\"employee_count\"] = count\n",
    "            filtered.append(d)\n",
    "    return filtered\n",
    "    \n",
    "    \n",
    "\n",
    "def add_assets(d, entry):\n",
    "    varieties = [v[\"variety\"] for v in d[\"asset\"][\"assets\"]]\n",
    "    types = [\"Media\", \"Network\", \"Person\", \"Server\", \"Term\", \"User Dev\", \"Embedded\", \"Unknown\", \"Other\"]\n",
    "    for t in types:\n",
    "        entry[\"asset.{}\".format(t)] = False\n",
    "\n",
    "    for val in varieties:\n",
    "        if val in [\"Unknown\", \"Other\"]:\n",
    "            entry[\"asset.{}\".format(val)] = True\n",
    "            continue\n",
    "        for t in types:\n",
    "            if val.startswith(t[0]):\n",
    "                entry[\"asset.{}\".format(t)] = True\n",
    "                break\n",
    "\n",
    "def add_discovery_method(d, entry):\n",
    "    methods = [\"internal\", \"external\", \"partner\", \"other\", \"unknown\"]\n",
    "    for method in methods:\n",
    "        val = method in d[\"discovery_method\"]\n",
    "        entry[\"discover_method.{}\".format(method)] = val\n",
    "\n",
    "def add_actor(d, entry):\n",
    "    actors = [\"internal\", \"external\", \"partner\", \"unknown\"]\n",
    "    for actor in actors:\n",
    "        val = actor in d[\"actor\"]\n",
    "        entry[\"actor.{}\".format(actor)] = val\n",
    "\n",
    "def add_action(d, entry):\n",
    "    actions = [\"hacking\", \"malware\", \"social\", \"error\", \"misuse\", \"physical\", \"environmental\", \"unknown\"]\n",
    "    for action in actions:\n",
    "        val = action in d[\"action\"]\n",
    "        entry[\"action.{}\".format(action)] = val\n",
    "\n",
    "def add_industry(d, entry):\n",
    "    for _, ind in NAIC_CODES.items():\n",
    "        entry[\"industry.{}\".format(ind)] = False\n",
    "    entry[\"industry.Unknown\"] = False\n",
    "    ind = get_industry(d)\n",
    "    entry[\"industry.{}\".format(ind)] = True\n",
    "\n",
    "\n",
    "\n",
    "def add_attribute(d, entry):\n",
    "    fields = [\"confidentiality\", \"integrity\", \"availability\", \"unknown\", \"confidentiality.data_total\", \"availability.duration\"]\n",
    "    for f in fields:\n",
    "        entry[\"attribute.{}\".format(f)] = 0\n",
    "    for k, v in d[\"attribute\"].items():\n",
    "        entry[\"attribute.{}\".format(k)] += 1\n",
    "        if k == \"confidentiality\" and \"data_total\" in v:\n",
    "            entry[\"attribute.confidentiality.data_total\"] += v[\"data_total\"]\n",
    "\n",
    "        if k == \"availability\":\n",
    "            if \"unit\" not in v or v[\"unit\"] in [\"Seconds\", \"Never\", \"Unknown\", \"NA\"]:\n",
    "                continue\n",
    "            if v[\"unit\"] == \"Minutes\":\n",
    "                entry[\"attribute.availability.duration\"] += (v[\"value\"] / 60)\n",
    "            if v[\"unit\"] == \"Hours\":\n",
    "                entry[\"attribute.availability.duration\"] += v[\"value\"]\n",
    "            if v[\"unit\"] == \"Days\":\n",
    "                entry[\"attribute.availability.duration\"] += (v[\"value\"]*24)\n",
    "            if v[\"unit\"] == \"Weeks\":\n",
    "                entry[\"attribute.availability.duration\"] += (v[\"value\"]*24*7)\n",
    "            if v[\"unit\"] == \"Months\":\n",
    "                entry[\"attribute.availability.duration\"] += (v[\"value\"]*24*7*4)\n",
    "            if v[\"unit\"] == \"Years\":\n",
    "                entry[\"attribute.availability.duration\"] += (v[\"value\"]*52*7*24)\n",
    "\n",
    "def transform(d):\n",
    "    entry = {\n",
    "        # Victim Attributes\n",
    "        \"victim_id\": d[\"victim\"][\"victim_id\"],\n",
    "        \"incident_year\": d[\"timeline\"][\"incident\"][\"year\"],\n",
    "        \"employee_count\": d[\"victim\"][\"employee_count\"],\n",
    "\n",
    "        # Y value\n",
    "        \"loss_amount\": d[\"impact\"][\"overall_amount\"],\n",
    "    }\n",
    "    # so far good results with action and assets only\n",
    "    # Add X values\n",
    "    # add_actor(d, entry)\n",
    "    add_action(d, entry)\n",
    "    add_assets(d, entry)\n",
    "    # add_discovery_method(d, entry)\n",
    "    # add_industry(d, entry)\n",
    "    # add_attribute(d, entry)\n",
    "    return entry\n",
    "\n",
    "with open(VCDB_FILE_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total number of entries: {len(data)}\")\n",
    "\n",
    "data = filter_for_recorded_loss(data)\n",
    "print(f\"Number of entries with recorded loss: {len(data)}\") # X remain\n",
    "\n",
    "data = filter_for_victim_employee_count(data)\n",
    "print(f\"Number of entries with recorded loss && employee count: {len(data)}\") # X remain\n",
    "\n",
    "data = [d for d in data if get_industry(d) == \"Finance and Insurance\"]\n",
    "entries = []\n",
    "for d in data:\n",
    "    entries.append(transform(d))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "entries = sorted(entries, key=lambda item: item[\"victim_id\"])\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "\n",
    "for key in entries[0].keys():\n",
    "    if key != \"victim_id\" and key != \"industry\":\n",
    "        df[key] = df[key].astype(int)\n",
    "\n",
    "# to excel\n",
    "# Move Y column to 2nd col\n",
    "y = df[\"loss_amount\"]\n",
    "df = df.drop('loss_amount', axis='columns')\n",
    "df.insert(1, 'loss_amount', y)\n",
    "df.to_excel(VCDB_EXCEL_OUTPUT, sheet_name='NewSheet', index=False)\n",
    "\n",
    "# split X and Y, drop victim id\n",
    "df_x = df.drop(\"victim_id\", axis='columns')\n",
    "y = df[\"loss_amount\"]\n",
    "df_x = df_x.drop('loss_amount', axis='columns')\n",
    "\n",
    "\n",
    "COLUMN_NAMES = df_x.columns.tolist()\n",
    "# print(COLUMN_NAMES)\n",
    "# print(df_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b140f1-18fa-404a-923a-d082058fea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature name  Relative weight - PC 1  Relative weight - PC 2\n",
      "0          incident_year                0.102681                0.067092\n",
      "1         employee_count                0.004173                0.063176\n",
      "2         action.hacking                0.074171                0.012674\n",
      "3         action.malware                0.043338                0.104992\n",
      "4          action.social                0.073752                0.174587\n",
      "5           action.error                0.038368                0.063199\n",
      "6          action.misuse                0.061336                0.071062\n",
      "7        action.physical                0.171989                0.054300\n",
      "8   action.environmental                0.000000                0.000000\n",
      "9         action.unknown                0.000000                0.000000\n",
      "10           asset.Media                0.006575                0.024519\n",
      "11         asset.Network                0.000000                0.000000\n",
      "12          asset.Person                0.073752                0.174587\n",
      "13          asset.Server                0.119971                0.017782\n",
      "14            asset.Term                0.169082                0.033468\n",
      "15        asset.User Dev                0.031456                0.088903\n",
      "16        asset.Embedded                0.000000                0.000000\n",
      "17         asset.Unknown                0.029355                0.049660\n",
      "18           asset.Other                0.000000                0.000000\n",
      "\n",
      "            feature name  Relative weight - PC 1\n",
      "0        action.physical                0.171989\n",
      "1             asset.Term                0.169082\n",
      "2           asset.Server                0.119971\n",
      "3          incident_year                0.102681\n",
      "4         action.hacking                0.074171\n",
      "5          action.social                0.073752\n",
      "6           asset.Person                0.073752\n",
      "7          action.misuse                0.061336\n",
      "8         action.malware                0.043338\n",
      "9           action.error                0.038368\n",
      "10        asset.User Dev                0.031456\n",
      "11         asset.Unknown                0.029355\n",
      "12           asset.Media                0.006575\n",
      "13        employee_count                0.004173\n",
      "14           asset.Other                0.000000\n",
      "15  action.environmental                0.000000\n",
      "16         asset.Network                0.000000\n",
      "17        asset.Embedded                0.000000\n",
      "18        action.unknown                0.000000\n",
      "\n",
      "            feature name  Relative weight - PC 2\n",
      "0          action.social                0.174587\n",
      "1           asset.Person                0.174587\n",
      "2         action.malware                0.104992\n",
      "3         asset.User Dev                0.088903\n",
      "4          action.misuse                0.071062\n",
      "5          incident_year                0.067092\n",
      "6           action.error                0.063199\n",
      "7         employee_count                0.063176\n",
      "8        action.physical                0.054300\n",
      "9          asset.Unknown                0.049660\n",
      "10            asset.Term                0.033468\n",
      "11           asset.Media                0.024519\n",
      "12          asset.Server                0.017782\n",
      "13        action.hacking                0.012674\n",
      "14           asset.Other                0.000000\n",
      "15  action.environmental                0.000000\n",
      "16         asset.Network                0.000000\n",
      "17        asset.Embedded                0.000000\n",
      "18        action.unknown                0.000000\n",
      "\n",
      "            feature name         coef\n",
      "0           asset.Person   7.4015e+06\n",
      "1          action.social   7.4015e+06\n",
      "2         action.malware   4.4136e+06\n",
      "3           asset.Server   3.9555e+06\n",
      "4         asset.User Dev   3.5436e+06\n",
      "5         action.hacking   2.4004e+06\n",
      "6         employee_count   1.8466e+06\n",
      "7          action.misuse   3.6217e+05\n",
      "8            asset.Other   0.0000e+00\n",
      "9   action.environmental   0.0000e+00\n",
      "10        action.unknown   0.0000e+00\n",
      "11         asset.Network   0.0000e+00\n",
      "12        asset.Embedded   0.0000e+00\n",
      "13         asset.Unknown  -2.4593e+05\n",
      "14          action.error  -2.7567e+05\n",
      "15           asset.Media  -4.1394e+05\n",
      "16         incident_year  -1.9958e+06\n",
      "17       action.physical  -4.8988e+06\n",
      "18            asset.Term  -5.3495e+06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def pca(X, n_components):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) on the given data.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): The input data matrix of shape (n_samples, n_features).\n",
    "        n_components (int): The number of principal components to retain.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The reduced data matrix of shape (n_samples, n_components).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Center the data\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_centered = X - X_mean\n",
    "\n",
    "    # 2. Compute the covariance matrix\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "\n",
    "    # 3. Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # 4. Sort the eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # 5. Select the top n_components eigenvectors\n",
    "    selected_eigenvectors = sorted_eigenvectors[:, :n_components]\n",
    "    selected_eigenvalues = sorted_eigenvalues[:n_components]\n",
    "\n",
    "    # print(selected_eigenvectors)\n",
    "    # 7. Calculate explained variance\n",
    "    total_variance = np.sum(sorted_eigenvalues)\n",
    "    explained_variance = selected_eigenvalues / total_variance\n",
    "\n",
    "    # print(f\"total: {total_variance}, captured: {explained_variance}\")\n",
    "\n",
    "\n",
    "    # 6. Project the data onto the new subspace\n",
    "    X_reduced = np.dot(X_centered, selected_eigenvectors)\n",
    "\n",
    "    return X_reduced, selected_eigenvectors\n",
    "\n",
    "###  Basic regression in cleartext ###\n",
    "def basic_regression(matrix, Y):\n",
    "    # Extract the second column (index 1) and save it to a separate array\n",
    "    # Y = matrix[:, 1]\n",
    "\n",
    "    # Remove the second column from the original matrix\n",
    "    # X = np.delete(matrix, 1, axis=1)\n",
    "    X = matrix\n",
    "\n",
    "    # Compute X^T X\n",
    "    XT_X = np.dot(X.T, X)\n",
    "\n",
    "    # Compute the inverse of X^T X\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "\n",
    "    # Compute X^T Y\n",
    "    XT_Y = np.dot(X.T, Y)\n",
    "    \n",
    "    # print(\"XT_X:\", XT_X)\n",
    "    # print(\"XT_Y:\", XT_X)\n",
    "    # print(\"XT_X_inv:\", XT_X_inv)\n",
    "\n",
    "    # Compute beta = (X^T X)^-1 X^T Y\n",
    "    beta = np.dot(XT_X_inv, XT_Y)\n",
    "\n",
    "    Y_pred = np.dot(X, beta)\n",
    "    ssr = 0\n",
    "    for i in range(len(Y_pred)):\n",
    "        ssr += (Y_pred[i] - Y[i]) ** 2\n",
    "    print(ssr, len(Y_pred))\n",
    "    r2 = r2_score(Y, Y_pred)\n",
    "\n",
    "\n",
    "    return beta, r2\n",
    "\n",
    "def pretty_print_model(model):\n",
    "    data = {\n",
    "        \"Model\": [\"OLS\"],\n",
    "        \"No. Observations\": [model[\"Number of Observations\"]],\n",
    "        \"Df Residuals\": [model[\"Df Residuals\"]],\n",
    "        \"Df Model\": [model[\"Df Model\"]],\n",
    "    }\n",
    "    print(\"\\n===============================================================\")\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "\n",
    "    data = {\n",
    "        \"R-squared\": model[\"R-Squared\"],\n",
    "        \"Adj. R-squared\": model[\"Adjusted R-Squared\"],\n",
    "        \"F-statistic\": model[\"F-statistic\"],\n",
    "        \"Prob (F-statistic)\": model[\"Probability (F-statistic)\"],\n",
    "    }\n",
    "    print(\"===============================================================\")\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"coef\": [ format(x[0], '.4e') for x in model[\"Beta Coefficients\"]],\n",
    "        \"std err\": [ format(x, '.4e') for x in model[\"Standard Error\"]],\n",
    "        't': [ x[0] for x in model[\"t-Stat\"]],\n",
    "        'P>|t|': [ x[0] for x in model['P>|t|']],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"===============================================================\")\n",
    "    print(df)\n",
    "\n",
    "    print(\"===============================================================\\n\")\n",
    "    \n",
    "\n",
    "PRIVATE_DATA_SRCX = df_x.to_numpy()\n",
    "PRIVATE_DATA_SRCY = y\n",
    "NUM_FIRMS = len(df_x)\n",
    "NUM_DIM = 5\n",
    "\n",
    "def get_private_data(firm_idx):\n",
    "    return PRIVATE_DATA_SRCX[firm_idx], PRIVATE_DATA_SRCY[firm_idx]\n",
    "\n",
    "def private_decrypt(firm_idx, cipher):\n",
    "    return cipher\n",
    "\n",
    "def encrypt(x, pubK):\n",
    "    return x\n",
    "\n",
    "def combine_decryptions(ciphers):\n",
    "    \"\"\"\n",
    "    Agg = ciphers[0]\n",
    "    for i in range(1, len(ciphers)):\n",
    "        Agg += ciphers[i]\n",
    "    \"\"\"\n",
    "    return ciphers[0]\n",
    "\n",
    "def typical_analysis(X, Y):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    # print(f\"Scaled X: {X}\")\n",
    "    \n",
    "    df_red, eigen = pca(X, NUM_DIM)\n",
    "    # print(f\"Eigen vectors: {eigen}\")\n",
    "\n",
    "    Y = np.array(Y)\n",
    "    Y = Y.reshape((len(X), 1))\n",
    "    \n",
    "    df_red = np.hstack((np.ones((len(Y), 1)), df_red))\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "    model = sm.OLS(Y, df_red)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "def decrypt(cipher, num_firms):\n",
    "    partial_decrypt = []\n",
    "    \n",
    "    for i in range(0, num_firms):\n",
    "        partial_decrypt.append(private_decrypt(i, cipher))\n",
    "    \n",
    "    Agg = combine_decryptions(partial_decrypt)\n",
    "    return Agg\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class AggComputation(Enum):\n",
    "    MEAN = 1\n",
    "    STD_ERR = 2\n",
    "    COVARIANCE = 3\n",
    "\n",
    "def private_compute(firm_idx, step, pk, parameters):\n",
    "    x, y = get_private_data(firm_idx)\n",
    "    # add constant parameter\n",
    "    x = np.hstack((1, x))\n",
    "    \n",
    "    ### STEP 0 ###\n",
    "    if step == 0:\n",
    "        return encrypt(x, pk)\n",
    "\n",
    "    ### STEP 1 ###\n",
    "    if step == 1:\n",
    "        means = parameters[\"means\"]\n",
    "        diff = []\n",
    "        for i in range(len(x)):\n",
    "            diff.append((x[i] - means[i])**2)\n",
    "        return encrypt(np.array(diff), pk)\n",
    "\n",
    "    ### STEP 2 ###\n",
    "    if step == 2:\n",
    "        means, sigmas = parameters[\"means\"], parameters[\"sigmas\"]\n",
    "        z = []\n",
    "        # skip first (constant) parameter\n",
    "        for i in range(1, len(x)):\n",
    "            if sigmas[i] == 0:\n",
    "                z.append(0)\n",
    "            else:\n",
    "                z.append((x[i] - means[i])/ sigmas[i])\n",
    "        z = np.array(z).reshape((1, len(z)))\n",
    "        return encrypt(np.dot(z.T, z), pk)\n",
    "\n",
    "    ### STEP 3 ###\n",
    "    if step == 3:\n",
    "        means, sigmas, eigen = parameters[\"means\"], parameters[\"sigmas\"], parameters[\"eigens\"]\n",
    "        z = []\n",
    "        # skip first (constant) parameter\n",
    "        for i in range(1, len(x)):\n",
    "            if sigmas[i] == 0:\n",
    "                z.append(0)\n",
    "            else:\n",
    "                z.append((x[i] - means[i])/ sigmas[i])\n",
    "        z = np.array(z).reshape((1, len(z)))\n",
    "        red_x = np.dot(z, eigen)\n",
    "        red_x = np.hstack((np.array(1).reshape(1,1), red_x))\n",
    "        \n",
    "        return (encrypt(np.dot(red_x.T, red_x), pk), encrypt(np.dot(red_x.T, y), pk), encrypt(np.dot(y.T, y), pk))                \n",
    "\n",
    "def OLS_regression(XT_X, XT_Y, YT_Y):\n",
    "    # Compute the inverse of X^T X\n",
    "    XT_X_inv = np.linalg.inv(XT_X)\n",
    "\n",
    "    # Compute beta = (X^T X)^-1 X^T Y\n",
    "    beta = np.dot(XT_X_inv, XT_Y)\n",
    "    xb = np.dot(XT_X[0], beta)\n",
    "    B_BT = np.dot(beta, beta.T)\n",
    "    B_BT_XT_X = np.dot(B_BT, XT_X)\n",
    "    sum_xb2 = np.sum(np.diagonal(B_BT_XT_X.T))\n",
    "    no_obvs = int(XT_X[0][0])\n",
    "\n",
    "    sum_sq_resid = YT_Y - (2 * np.dot(XT_Y.T, beta)) + sum_xb2\n",
    "    sum_sq_resid = sum_sq_resid[0]\n",
    "    df_resid = no_obvs - (NUM_DIM + 1)\n",
    "    mse = resid_var = sum_sq_resid / df_resid\n",
    "    df_reg = NUM_DIM \n",
    "    reg_sum_sq =  sum_xb2 - (2 * (XT_Y[0] / no_obvs) * xb) + (no_obvs * ((XT_Y[0] / no_obvs) ** 2))\n",
    "    reg_sum_sq = reg_sum_sq[0]\n",
    "    msr = reg_sum_sq / df_reg\n",
    "    f_stat = msr / mse\n",
    "    \n",
    "    tss = sum_sq_resid + reg_sum_sq\n",
    "    f_sig  = stats.f.sf(f_stat, df_reg, df_resid)\n",
    "    r_sq = 1 - (sum_sq_resid / tss)\n",
    "    \n",
    "    std_err = (resid_var * np.diagonal(XT_X_inv)) ** 0.5\n",
    "    t_stat = []\n",
    "    p_val = []\n",
    "    for i, coef in enumerate(beta):\n",
    "        t_val = coef/std_err[i]\n",
    "        t_stat.append(t_val)\n",
    "        p_val.append(2 * stats.t.sf(abs(t_val), no_obvs - NUM_DIM- 1))\n",
    "\n",
    "    t_stat = np.array(t_stat)\n",
    "    p_val = np.array(p_val)\n",
    "\n",
    "\n",
    "    adjusted_rsq = 1 - ((1 - r_sq) * (no_obvs - 1) / (no_obvs - NUM_DIM - 1))\n",
    "\n",
    "    model = {\n",
    "        \"Beta Coefficients\" : beta,\n",
    "        \"Standard Error\": std_err.T,\n",
    "        \"t-Stat\": t_stat,\n",
    "        \"P>|t|\": p_val,\n",
    "        \"Df Residuals\": df_resid,\n",
    "        \"Df Model\": df_reg,\n",
    "        \"Number of Observations\": no_obvs,\n",
    "        \"R-Squared\": r_sq,\n",
    "        \"Adjusted R-Squared\": adjusted_rsq,\n",
    "        \"F-statistic\": f_stat,\n",
    "        \"Sum of Squared Residuals\": sum_sq_resid, # good val\n",
    "        \"Probability (F-statistic)\": f_sig,\n",
    "    }\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\" Takes place after key distribution \"\"\"\n",
    "def mpc_analysis(pubK, num_firms):\n",
    "\n",
    "    ### STEP 0 ###\n",
    "    step = 0\n",
    "    Agg_c = private_compute(0, step, pubK, None)\n",
    "    for i in range(1, num_firms):\n",
    "        Agg_c += private_compute(i, step, pubK, None)\n",
    "    sum_X = decrypt(Agg_c, num_firms)\n",
    "    num_features = len(sum_X)\n",
    "    num_X = sum_X[0]\n",
    "    means = []\n",
    "    for i in range(num_features):\n",
    "        means.append(sum_X[i]/sum_X[0])\n",
    "\n",
    "\n",
    "    ### STEP 1 ###\n",
    "    step = 1\n",
    "    Agg_c = private_compute(0, step, pubK, {\"means\": means})\n",
    "    for i in range(1, num_firms):\n",
    "        Agg_c += private_compute(i, step, pubK, {\"means\": means})\n",
    "    Agg = decrypt(Agg_c, num_firms)\n",
    "    sigmas = []\n",
    "    for i in range(num_features):\n",
    "        val = (Agg[i] / num_X ) ** 0.5\n",
    "        sigmas.append(val)\n",
    "\n",
    "    ### STEP 2 ###\n",
    "    step = 2\n",
    "    Agg_c = private_compute(0, step, pubK, {\"means\": means, \"sigmas\": sigmas})\n",
    "    for i in range(1, num_firms):\n",
    "        Agg_c += np.array(private_compute(i, step, pubK, {\n",
    "            \"means\": means, \n",
    "            \"sigmas\": sigmas\n",
    "        }))\n",
    "\n",
    "    Cov = decrypt(Agg_c, num_firms)\n",
    "    eigen_vals, eigen_vects = np.linalg.eig(Cov)\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors in descending order, \n",
    "    # and select the top NUM_DIM eigenvectors\n",
    "    sorted_indices = np.argsort(eigen_vals)[::-1]\n",
    "    sorted_eigenvalues = eigen_vals[sorted_indices]\n",
    "    sorted_eigenvectors = eigen_vects[:, sorted_indices]\n",
    "\n",
    "    selected_eigenvectors = sorted_eigenvectors[:, :NUM_DIM]\n",
    "    selected_eigenvalues = sorted_eigenvalues[:NUM_DIM]\n",
    "\n",
    "    ### STEP 3 ###\n",
    "    step = 3\n",
    "    Agg_covx, Agg_covxy, Agg_covy = private_compute(0, step, pubK, {\n",
    "        \"means\": means,\n",
    "        \"sigmas\": sigmas,\n",
    "        \"eigens\": selected_eigenvectors\n",
    "    })\n",
    "    for i in range(1, num_firms):\n",
    "        covx, covxy, covy = private_compute(i, step, pubK, {\n",
    "            \"means\": means, \n",
    "            \"sigmas\": sigmas, \n",
    "            \"eigens\": selected_eigenvectors\n",
    "        })\n",
    "        Agg_covx += covx\n",
    "        Agg_covxy += covxy\n",
    "        Agg_covy += covy\n",
    "    \n",
    "    XT_X, XT_Y, YT_Y = ( \n",
    "        decrypt(Agg_covx, num_firms),\n",
    "        decrypt(Agg_covxy, num_firms),\n",
    "        decrypt(Agg_covy, num_firms)\n",
    "    )\n",
    "    # perform the regression\n",
    "    model = OLS_regression(XT_X, XT_Y, YT_Y)\n",
    "\n",
    "    return model, selected_eigenvectors\n",
    "    \n",
    "\n",
    "# typical_analysis(df_x, y)\n",
    "# model, eigens = mpc_analysis(df_x, NUM_FIRMS)\n",
    "# pretty_print_model(model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# get relative feature weights for first two components\n",
    "\n",
    "PCAs = [[], []]\n",
    "for i in range(2):\n",
    "    vector = np.abs(eigens[:, i])\n",
    "    total_val = np.sum(vector)\n",
    "    for j in range(len(COLUMN_NAMES)):\n",
    "        val = (vector[j] / total_val)\n",
    "        PCAs[i].append(val)\n",
    "\n",
    "relative_weights = {\n",
    "    \"feature name\": COLUMN_NAMES,\n",
    "    \"Relative weight - PC 1\": PCAs[0],\n",
    "    \"Relative weight - PC 2\": PCAs[1],\n",
    "}\n",
    "\n",
    "sorted_indices = np.argsort(PCAs[0])[::-1]\n",
    "pca1 = {\n",
    "    \"feature name\": [COLUMN_NAMES[i] for i in sorted_indices],\n",
    "    \"Relative weight - PC 1\": [PCAs[0][i] for i in sorted_indices],\n",
    "}\n",
    "\n",
    "sorted_indices = np.argsort(PCAs[1])[::-1]\n",
    "pca2 = {\n",
    "    \"feature name\": [COLUMN_NAMES[i] for i in sorted_indices],\n",
    "    \"Relative weight - PC 2\": [PCAs[1][i] for i in sorted_indices],\n",
    "}\n",
    "\n",
    "\n",
    "rel = pd.DataFrame(relative_weights)\n",
    "print(rel)\n",
    "print()\n",
    "rel = pd.DataFrame(pca1)\n",
    "print(rel)\n",
    "print()\n",
    "rel = pd.DataFrame(pca2)\n",
    "print(rel)\n",
    "print()\n",
    "\n",
    "\n",
    "# get relative feature weights for first two components\n",
    "beta = model[\"Beta Coefficients\"]\n",
    "contributions = [0] * len(COLUMN_NAMES)\n",
    "for i in range(2):\n",
    "    vector = eigens[:, i]\n",
    "    # total_val = np.sum(vector)\n",
    "    for j in range(len(COLUMN_NAMES)):\n",
    "        val = vector[j] * beta[i+1]\n",
    "        contributions[j] += val[0]\n",
    "\n",
    "sorted_indices = np.argsort(contributions)[::-1]\n",
    "feat_coef = {\n",
    "    \"feature name\": [COLUMN_NAMES[i] for i in sorted_indices],\n",
    "    \"coef\": [format(contributions[i], '.4e') for i in sorted_indices]\n",
    "}\n",
    "rel = pd.DataFrame(feat_coef)\n",
    "print(rel)\n",
    "print()\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5abe86-b7e6-4d57-b645-c746f8fc221a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api302",
   "language": "python",
   "name": "api302"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
